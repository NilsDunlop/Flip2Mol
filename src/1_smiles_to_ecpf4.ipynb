{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be490bcf9d064755",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Project: Decoding Molecules From Fingerprints.\n",
    "## Group Members:\n",
    "### Qi Chen, e-mail: gusqichr@student.gu.se\n",
    "### Nils Dunlop, e-mail: gusdunlni@student.gu.se\n",
    "### Francisco Alejandro Erazo Piza, e-mail: guserafr@student.gu.se\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db70a18ceb7f41c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:33:57.204683500Z",
     "start_time": "2024-09-16T15:33:57.160085300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit import Chem\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb7232c",
   "metadata": {},
   "source": [
    "#### Convert SMILES to Fingerprints\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60f323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project root directory\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the project root to the Python path\n",
    "import sys\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Define the output directory for the chunks\n",
    "SAVE_DIR = os.path.join(PROJECT_ROOT, 'data/chunks')\n",
    "\n",
    "# Ensure the save directory exists\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Define the zip file path\n",
    "ZIP_FILE_PATH = os.path.join(PROJECT_ROOT, 'data/final_chembl.zip')\n",
    "\n",
    "# Define the combined parquet file path\n",
    "COMBINED_PARQUET_PATH = os.path.join(PROJECT_ROOT, 'data/combined_molecule_fingerprints.parquet')\n",
    "\n",
    "# Cores\n",
    "NUM_CORES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198a3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data_in_chunks(zip_file_path, chunksize=10000):\n",
    "    \"\"\"\n",
    "    Import data from a zip file containing a CSV in chunks.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
    "        file_list = z.namelist()\n",
    "        csv_filename = file_list[0]\n",
    "        with z.open(csv_filename) as f:\n",
    "            for chunk in pd.read_csv(f, chunksize=chunksize):\n",
    "                yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3795e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_smiles_df(df_chunk):\n",
    "    \"\"\"\n",
    "    Prepare a DataFrame with ChEMBL ID, SMILES, and Molecule column.\n",
    "    \"\"\"\n",
    "    smiles_df = df_chunk[['ChEMBL ID', 'smiles']].copy()\n",
    "    PandasTools.AddMoleculeColumnToFrame(smiles_df, 'smiles', 'Molecule')\n",
    "    return smiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a92f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fingerprint(mol):\n",
    "    \"\"\"\n",
    "    Generate ECFP4 fingerprint and sparse representation for a molecule.\n",
    "    \"\"\"\n",
    "    if mol is not None:\n",
    "        morgan_generator = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "        fp = morgan_generator.GetFingerprint(mol)\n",
    "        bit_vector = np.array(list(fp.ToBitString())).astype(int)\n",
    "        sparse_representation = list(np.where(bit_vector == 1)[0])\n",
    "        sparse_representation_str = ' '.join(map(str, sparse_representation))\n",
    "        return bit_vector, sparse_representation_str\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78ed547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fingerprints_parallel(smiles_df):\n",
    "    \"\"\"\n",
    "    Generate fingerprints for all molecules in parallel.\n",
    "    \"\"\"\n",
    "\n",
    "    results = Parallel(n_jobs=NUM_CORES)(delayed(generate_fingerprint)(mol) for mol in smiles_df['Molecule'])\n",
    "    bit_vectors, sparse_fingerprints = zip(*results)\n",
    "    smiles_df['FingerprintBits'] = list(bit_vectors)\n",
    "    smiles_df['SparseFingerprintBits'] = list(sparse_fingerprints)\n",
    "    return smiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea7c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(df_chunk, chunk_id):\n",
    "    \"\"\"\n",
    "    Process a single chunk of data.\n",
    "    \"\"\"\n",
    "    smiles_df = prepare_smiles_df(df_chunk)\n",
    "    smiles_df = generate_fingerprints_parallel(smiles_df)\n",
    "    smiles_df_filtered = smiles_df.drop(columns=['Molecule'])\n",
    "    file_name = os.path.join(SAVE_DIR, f'molecule_fingerprints_part_{chunk_id}.parquet')\n",
    "    smiles_df_filtered.to_parquet(file_name, compression='snappy')\n",
    "    print(f\"Processed and saved chunk {chunk_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1d4c72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved chunk 0\n",
      "Processed and saved chunk 1\n",
      "Processed and saved chunk 2\n",
      "Processed and saved chunk 3\n",
      "Processed and saved chunk 4\n",
      "Processed and saved chunk 5\n",
      "Processed and saved chunk 6\n",
      "Processed and saved chunk 7\n",
      "Processed and saved chunk 8\n",
      "Processed and saved chunk 9\n",
      "Processed and saved chunk 10\n",
      "Processed and saved chunk 11\n",
      "Processed and saved chunk 12\n",
      "Processed and saved chunk 13\n",
      "Processed and saved chunk 14\n",
      "Processed and saved chunk 15\n",
      "Processed and saved chunk 16\n",
      "Processed and saved chunk 17\n",
      "Processed and saved chunk 18\n",
      "Processed and saved chunk 19\n",
      "Processed and saved chunk 20\n",
      "Processed and saved chunk 21\n",
      "Processed and saved chunk 22\n",
      "Processed and saved chunk 23\n",
      "Processed and saved chunk 24\n",
      "Processed and saved chunk 25\n",
      "Processed and saved chunk 26\n",
      "Processed and saved chunk 27\n",
      "All chunks processed and saved as individual parquet files.\n"
     ]
    }
   ],
   "source": [
    "chunksize = 50000\n",
    "    \n",
    "# Process data in chunks\n",
    "for chunk_id, df_chunk in enumerate(import_data_in_chunks(ZIP_FILE_PATH, chunksize)):\n",
    "    process_chunk(df_chunk, chunk_id)\n",
    "\n",
    "print(\"All chunks processed and saved as individual parquet files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
